{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aabb78f-a4e3-4800-ad3c-581eac544c84",
   "metadata": {},
   "source": [
    "### Import Nessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0395af-c021-433f-b051-197f4b2e7b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abcbfff5-5995-4b0b-9522-51261a65da06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f24528-8b10-4a73-b334-88546b87efed",
   "metadata": {},
   "source": [
    "###  Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3021b85-f795-46c0-a57d-a174341d90a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <th>pickup_community_area</th>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <th>...</th>\n",
       "      <th>company</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_location</th>\n",
       "      <th>trip_start_day</th>\n",
       "      <th>trip_start_month</th>\n",
       "      <th>trip_start_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b0ff5638ed5905d99da624abc903b967f868cfd</td>\n",
       "      <td>3426c4a607f9804cc5f33ecb1cab61f70f63b3f0593c94...</td>\n",
       "      <td>2019-03-11 12:45:00+00:00</td>\n",
       "      <td>2019-03-11 12:45:00+00:00</td>\n",
       "      <td>340</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.703184e+10</td>\n",
       "      <td>1.703128e+10</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24 Seven Taxi</td>\n",
       "      <td>41.880994</td>\n",
       "      <td>-87.632746</td>\n",
       "      <td>POINT (-87.6327464887 41.8809944707)</td>\n",
       "      <td>41.885300</td>\n",
       "      <td>-87.642808</td>\n",
       "      <td>POINT (-87.6428084655 41.8853000224)</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb868659d19997db5a97e8ae22097ce12fa3c8e0</td>\n",
       "      <td>5776c9e3fe3235f1c036220f324b07aa8728ebd6641bfc...</td>\n",
       "      <td>2019-03-11 22:45:00+00:00</td>\n",
       "      <td>2019-03-11 23:15:00+00:00</td>\n",
       "      <td>1213</td>\n",
       "      <td>7.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Chicago Carriage Cab Corp</td>\n",
       "      <td>41.878866</td>\n",
       "      <td>-87.625192</td>\n",
       "      <td>POINT (-87.6251921424 41.8788655841)</td>\n",
       "      <td>41.944227</td>\n",
       "      <td>-87.655998</td>\n",
       "      <td>POINT (-87.6559981815 41.9442266014)</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3cd47551b2424db69e6923b7ae4929fd7f04eed2</td>\n",
       "      <td>40dd26181941ac03ca95b3d4cf2f0d12b34ae0338e688b...</td>\n",
       "      <td>2023-05-12 07:00:00+00:00</td>\n",
       "      <td>2023-05-12 07:15:00+00:00</td>\n",
       "      <td>1134</td>\n",
       "      <td>5.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Flash Cab</td>\n",
       "      <td>41.900070</td>\n",
       "      <td>-87.720918</td>\n",
       "      <td>POINT (-87.7209182385 41.9000696026)</td>\n",
       "      <td>41.874005</td>\n",
       "      <td>-87.663518</td>\n",
       "      <td>POINT (-87.6635175498 41.874005383)</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ded2218e2090f75607f2b03d00265ef69d9d71f</td>\n",
       "      <td>1d72db3a18692cc5b5e4ea41bb1de0e45d4149b495dbd0...</td>\n",
       "      <td>2021-06-13 12:45:00+00:00</td>\n",
       "      <td>2021-06-13 13:00:00+00:00</td>\n",
       "      <td>563</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Flash Cab</td>\n",
       "      <td>41.965812</td>\n",
       "      <td>-87.655879</td>\n",
       "      <td>POINT (-87.6558787862 41.96581197)</td>\n",
       "      <td>41.986712</td>\n",
       "      <td>-87.663416</td>\n",
       "      <td>POINT (-87.6634164054 41.9867117999)</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67fd7d0b6a607a3d228738481960eb1dd14079ad</td>\n",
       "      <td>48c3c22d766613be3982924a72efdc03758b9666b3996b...</td>\n",
       "      <td>2023-01-09 10:30:00+00:00</td>\n",
       "      <td>2023-01-09 10:45:00+00:00</td>\n",
       "      <td>420</td>\n",
       "      <td>1.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Taxicab Insurance Agency, LLC</td>\n",
       "      <td>41.874005</td>\n",
       "      <td>-87.663518</td>\n",
       "      <td>POINT (-87.6635175498 41.874005383)</td>\n",
       "      <td>41.874005</td>\n",
       "      <td>-87.663518</td>\n",
       "      <td>POINT (-87.6635175498 41.874005383)</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 unique_key  \\\n",
       "0  4b0ff5638ed5905d99da624abc903b967f868cfd   \n",
       "1  eb868659d19997db5a97e8ae22097ce12fa3c8e0   \n",
       "2  3cd47551b2424db69e6923b7ae4929fd7f04eed2   \n",
       "3  5ded2218e2090f75607f2b03d00265ef69d9d71f   \n",
       "4  67fd7d0b6a607a3d228738481960eb1dd14079ad   \n",
       "\n",
       "                                             taxi_id  \\\n",
       "0  3426c4a607f9804cc5f33ecb1cab61f70f63b3f0593c94...   \n",
       "1  5776c9e3fe3235f1c036220f324b07aa8728ebd6641bfc...   \n",
       "2  40dd26181941ac03ca95b3d4cf2f0d12b34ae0338e688b...   \n",
       "3  1d72db3a18692cc5b5e4ea41bb1de0e45d4149b495dbd0...   \n",
       "4  48c3c22d766613be3982924a72efdc03758b9666b3996b...   \n",
       "\n",
       "        trip_start_timestamp         trip_end_timestamp  trip_seconds  \\\n",
       "0  2019-03-11 12:45:00+00:00  2019-03-11 12:45:00+00:00           340   \n",
       "1  2019-03-11 22:45:00+00:00  2019-03-11 23:15:00+00:00          1213   \n",
       "2  2023-05-12 07:00:00+00:00  2023-05-12 07:15:00+00:00          1134   \n",
       "3  2021-06-13 12:45:00+00:00  2021-06-13 13:00:00+00:00           563   \n",
       "4  2023-01-09 10:30:00+00:00  2023-01-09 10:45:00+00:00           420   \n",
       "\n",
       "   trip_miles  pickup_census_tract  dropoff_census_tract  \\\n",
       "0        0.84         1.703184e+10          1.703128e+10   \n",
       "1        7.66                  NaN                   NaN   \n",
       "2        5.47                  NaN                   NaN   \n",
       "3        1.62                  NaN                   NaN   \n",
       "4        1.40                  NaN                   NaN   \n",
       "\n",
       "   pickup_community_area  dropoff_community_area  ...  \\\n",
       "0                   32.0                    28.0  ...   \n",
       "1                   32.0                     6.0  ...   \n",
       "2                   23.0                    28.0  ...   \n",
       "3                    3.0                    77.0  ...   \n",
       "4                   28.0                    28.0  ...   \n",
       "\n",
       "                         company  pickup_latitude  pickup_longitude  \\\n",
       "0                  24 Seven Taxi        41.880994        -87.632746   \n",
       "1      Chicago Carriage Cab Corp        41.878866        -87.625192   \n",
       "2                      Flash Cab        41.900070        -87.720918   \n",
       "3                      Flash Cab        41.965812        -87.655879   \n",
       "4  Taxicab Insurance Agency, LLC        41.874005        -87.663518   \n",
       "\n",
       "                        pickup_location  dropoff_latitude dropoff_longitude  \\\n",
       "0  POINT (-87.6327464887 41.8809944707)         41.885300        -87.642808   \n",
       "1  POINT (-87.6251921424 41.8788655841)         41.944227        -87.655998   \n",
       "2  POINT (-87.7209182385 41.9000696026)         41.874005        -87.663518   \n",
       "3    POINT (-87.6558787862 41.96581197)         41.986712        -87.663416   \n",
       "4   POINT (-87.6635175498 41.874005383)         41.874005        -87.663518   \n",
       "\n",
       "                       dropoff_location  trip_start_day  trip_start_month  \\\n",
       "0  POINT (-87.6428084655 41.8853000224)              11                 3   \n",
       "1  POINT (-87.6559981815 41.9442266014)              11                 3   \n",
       "2   POINT (-87.6635175498 41.874005383)              12                 5   \n",
       "3  POINT (-87.6634164054 41.9867117999)              13                 6   \n",
       "4   POINT (-87.6635175498 41.874005383)               9                 1   \n",
       "\n",
       "  trip_start_hour  \n",
       "0              12  \n",
       "1              22  \n",
       "2               7  \n",
       "3              12  \n",
       "4              10  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading CSV file in the GCS bucket\n",
    "# gcs_path = 'gs://cab_bucket/cab-gcp-vertex-pipelines1/data/Final_Chicago_Train.csv'\n",
    "gcs_path = 'Final_Chicago_Train.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(gcs_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "061e78f9-d530-4098-a294-eea105d7b858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the 'trip_start_timestamp' to datetime if it's not already.\n",
    "df['trip_start_timestamp'] = pd.to_datetime(df['trip_start_timestamp'])\n",
    "\n",
    "# Extract hour, day, and month from the timestamp\n",
    "df['trip_start_hour'] = df['trip_start_timestamp'].dt.hour\n",
    "df['trip_start_day'] = df['trip_start_timestamp'].dt.day\n",
    "df['trip_start_month'] = df['trip_start_timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83e9e2f0-0ae2-4971-9e5a-ca549223ad37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['trip_end_timestamp'] = pd.to_datetime(df['trip_end_timestamp'])\n",
    "\n",
    "df['trip_end_hour'] = df['trip_end_timestamp'].dt.hour\n",
    "df['trip_end_day'] = df['trip_end_timestamp'].dt.day\n",
    "df['trip_end_month'] = df['trip_end_timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52defa5e-dc13-4e0a-8bc5-92f3f07f628e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['unique_key', 'taxi_id', 'trip_start_timestamp', \n",
    "                   'trip_end_timestamp', 'dropoff_location', 'pickup_location']\n",
    "# Dropping unnecessary columns \n",
    "df= df.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2094d-e2e7-4246-9a49-c0a5eeb870c6",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23d1cae-314f-4674-9c1f-fe5a73d4559e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def one_hot_encode(values, num_categories):\n",
    "    \"\"\"One-hot encode the values.\"\"\"\n",
    "    categories = sorted(set(values.dropna()))  # Handle NaN by dropping\n",
    "    one_hot_encoded = []\n",
    "    for v in values:\n",
    "        encoding = [1 if v == category else 0 for category in categories]\n",
    "        one_hot_encoded.append(encoding)\n",
    "    return pd.DataFrame(one_hot_encoded, columns=[f\"{values.name}_{c}\" for c in categories], index=values.index)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    numerical_features = ['trip_miles', 'trip_seconds', 'tips', 'tolls', 'extras', 'trip_total']\n",
    "    bucket_features = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\n",
    "    categorical_numerical_features = [\n",
    "        'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
    "        'trip_end_hour', 'trip_end_day', 'trip_end_month',\n",
    "        'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
    "        'dropoff_community_area'\n",
    "    ]\n",
    "    categorical_string_features = ['payment_type', 'company']\n",
    "    \n",
    "    # Handling missing values and scaling numerical features\n",
    "    for feature in numerical_features:\n",
    "        df[feature] = SimpleImputer(strategy='mean').fit_transform(df[[feature]])\n",
    "        df[feature] = StandardScaler().fit_transform(df[[feature]])\n",
    "    \n",
    "    # Bucketizing geographical features\n",
    "    for feature in bucket_features:\n",
    "        df[feature] = SimpleImputer(strategy='mean').fit_transform(df[[feature]])\n",
    "        discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "        df[feature] = discretizer.fit_transform(df[[feature]])\n",
    "    \n",
    "    # One-hot encoding for categorical string features\n",
    "    for feature in categorical_string_features:\n",
    "        df_filled = SimpleImputer(strategy='constant', fill_value='missing').fit_transform(df[[feature]].astype(str))\n",
    "        df_encoded = one_hot_encode(pd.Series(df_filled.flatten(), name=feature), num_categories=None)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "        df.drop(columns=[feature], inplace=True)\n",
    "    \n",
    "    # One-hot encoding for categorical numerical features\n",
    "    for feature in categorical_numerical_features:\n",
    "        df_filled = SimpleImputer(strategy='most_frequent').fit_transform(df[[feature]].astype(str))\n",
    "        df_encoded = one_hot_encode(pd.Series(df_filled.flatten(), name=feature), num_categories=None)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "        df.drop(columns=[feature], inplace=True)\n",
    "    \n",
    "    # Fill missing values for the label (fare)\n",
    "    df['fare'] = SimpleImputer(strategy='mean').fit_transform(df[['fare']])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d22093-77ca-49f5-9cf1-54c42d19bef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>fare</th>\n",
       "      <th>tips</th>\n",
       "      <th>tolls</th>\n",
       "      <th>extras</th>\n",
       "      <th>trip_total</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>dropoff_community_area_71.0</th>\n",
       "      <th>dropoff_community_area_72.0</th>\n",
       "      <th>dropoff_community_area_73.0</th>\n",
       "      <th>dropoff_community_area_74.0</th>\n",
       "      <th>dropoff_community_area_75.0</th>\n",
       "      <th>dropoff_community_area_76.0</th>\n",
       "      <th>dropoff_community_area_77.0</th>\n",
       "      <th>dropoff_community_area_8.0</th>\n",
       "      <th>dropoff_community_area_9.0</th>\n",
       "      <th>dropoff_community_area_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.390372</td>\n",
       "      <td>-0.506731</td>\n",
       "      <td>5.75</td>\n",
       "      <td>-0.075512</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>-0.103364</td>\n",
       "      <td>-0.262552</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081204</td>\n",
       "      <td>0.322058</td>\n",
       "      <td>21.50</td>\n",
       "      <td>-0.628153</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>-0.044446</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038530</td>\n",
       "      <td>0.055922</td>\n",
       "      <td>16.75</td>\n",
       "      <td>-0.628153</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>-0.103364</td>\n",
       "      <td>-0.106592</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.269912</td>\n",
       "      <td>-0.411943</td>\n",
       "      <td>8.00</td>\n",
       "      <td>-0.628153</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>-0.103364</td>\n",
       "      <td>-0.267139</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.347157</td>\n",
       "      <td>-0.438678</td>\n",
       "      <td>7.25</td>\n",
       "      <td>-0.628153</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>-0.103364</td>\n",
       "      <td>-0.280901</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_seconds  trip_miles   fare      tips     tolls    extras  trip_total  \\\n",
       "0     -0.390372   -0.506731   5.75 -0.075512 -0.020947 -0.103364   -0.262552   \n",
       "1      0.081204    0.322058  21.50 -0.628153 -0.020947 -0.044446   -0.001090   \n",
       "2      0.038530    0.055922  16.75 -0.628153 -0.020947 -0.103364   -0.106592   \n",
       "3     -0.269912   -0.411943   8.00 -0.628153 -0.020947 -0.103364   -0.267139   \n",
       "4     -0.347157   -0.438678   7.25 -0.628153 -0.020947 -0.103364   -0.280901   \n",
       "\n",
       "   pickup_latitude  pickup_longitude  dropoff_latitude  ...  \\\n",
       "0              6.0               7.0               6.0  ...   \n",
       "1              6.0               7.0               7.0  ...   \n",
       "2              6.0               5.0               6.0  ...   \n",
       "3              8.0               6.0               9.0  ...   \n",
       "4              6.0               6.0               6.0  ...   \n",
       "\n",
       "   dropoff_community_area_71.0  dropoff_community_area_72.0  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   dropoff_community_area_73.0  dropoff_community_area_74.0  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   dropoff_community_area_75.0  dropoff_community_area_76.0  \\\n",
       "0                            0                            0   \n",
       "1                            0                            0   \n",
       "2                            0                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   dropoff_community_area_77.0  dropoff_community_area_8.0  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            1                           0   \n",
       "4                            0                           0   \n",
       "\n",
       "   dropoff_community_area_9.0  dropoff_community_area_nan  \n",
       "0                           0                           0  \n",
       "1                           0                           0  \n",
       "2                           0                           0  \n",
       "3                           0                           0  \n",
       "4                           0                           0  \n",
       "\n",
       "[5 rows x 728 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming your DataFrame after dropping columns is named df\n",
    "df_processed = preprocess_data(df)\n",
    "\n",
    "# Now you can display the processed DataFrame\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906623fe-bc89-4806-87cd-03246c5da323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trip_seconds', 'trip_miles', 'pickup_census_tract',\n",
       "       'dropoff_census_tract', 'pickup_community_area',\n",
       "       'dropoff_community_area', 'fare', 'tips', 'tolls', 'extras',\n",
       "       'trip_total', 'payment_type', 'company', 'pickup_latitude',\n",
       "       'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude',\n",
       "       'trip_start_day', 'trip_start_month', 'trip_start_hour',\n",
       "       'trip_end_hour', 'trip_end_day', 'trip_end_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e36b9-68e1-469f-9ce0-f7d4d0933870",
   "metadata": {},
   "source": [
    "### Defining X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6776bd0f-041a-4641-9b14-c0d6c80376ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y =df_processed['fare']\n",
    "# Dropping unnecessary columns \n",
    "X= df_processed.drop(columns='fare')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae7cbb-3b47-480e-9c06-8c9dbca9a8d2",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2593fcb1-56dc-44ee-b24f-c37b5abb1902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615e01d-df71-4bb2-ab5c-5aea2228e03c",
   "metadata": {},
   "source": [
    "### Fitting the model and evaluating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d282ec5-9a15-407c-9e8a-585154cb96e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 322788644909691264.0000, RMSE: 568144915.4130, R2: -903044636083671.0000\n",
      "Decision Tree - MSE: 23.9307, RMSE: 4.8919, R2: 0.9331\n",
      "Random Forest - MSE: 42.9145, RMSE: 6.5509, R2: 0.8799\n",
      "Gradient Boosting - MSE: 36.2956, RMSE: 6.0246, R2: 0.8985\n",
      "ANN - MSE: 6.2948, RMSE: 2.5089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Define the ANN functions\n",
    "def _build_ann_model():\n",
    "    \"\"\"Creates a simple artificial neural network model.\"\"\"\n",
    "    ann_model = MLPRegressor(hidden_layer_sizes=(100, 70, 50, 20),\n",
    "                             activation='relu',\n",
    "                             solver='adam',\n",
    "                             learning_rate_init=0.0005,\n",
    "                             random_state=42)\n",
    "    return ann_model\n",
    "\n",
    "def _train_ann_model(model, train_data, train_labels):\n",
    "    \"\"\"Trains the artificial neural network model.\"\"\"\n",
    "    model.fit(train_data, train_labels)\n",
    "\n",
    "def _evaluate_ann_model(model, eval_data, eval_labels):\n",
    "    \"\"\"Evaluates the artificial neural network model.\"\"\"\n",
    "    eval_predictions = model.predict(eval_data)\n",
    "    mse = ((eval_predictions - eval_labels) ** 2).mean()\n",
    "    return mse\n",
    "\n",
    "# Initialize models including the ANN model\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"ANN\": _build_ann_model()  \n",
    "}\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    if isinstance(model, MLPRegressor):\n",
    "        # Train and evaluate ANN model separately\n",
    "        _train_ann_model(model, X_train, y_train)\n",
    "        mse = _evaluate_ann_model(model, X_test, y_test)\n",
    "        return mse, np.sqrt(mse), None  # No R2 score for ANN model\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        return mse, rmse, r2\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    mse, rmse, r2 = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results[model_name] = {\"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "# Print the results\n",
    "for model_name, metrics in results.items():\n",
    "    if metrics['R2'] is not None:\n",
    "        print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, RMSE: {metrics['RMSE']:.4f}, R2: {metrics['R2']:.4f}\")\n",
    "    else:\n",
    "        print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, RMSE: {metrics['RMSE']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c3888-ba8c-4c07-93c6-03ee12f9ce6e",
   "metadata": {},
   "source": [
    "##### Here ANN model is giving the best result compared to other models. So we are selecting the ANN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf95a6-3bd7-434d-a274-f3c268255f8b",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694fd0be-6275-4c3b-a3fa-95c89f1f5fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Define the ANN functions\n",
    "def _build_ann_model():\n",
    "    \"\"\"Creates a simple artificial neural network model.\"\"\"\n",
    "    ann_model = MLPRegressor(random_state=42)\n",
    "    return ann_model\n",
    "def _train_ann_model(model, train_data, train_labels):\n",
    "    \"\"\"Trains the artificial neural network model.\"\"\"\n",
    "    model.fit(train_data, train_labels)\n",
    "def _evaluate_ann_model(model, eval_data, eval_labels):\n",
    "    \"\"\"Evaluates the artificial neural network model.\"\"\"\n",
    "    eval_predictions = model.predict(eval_data)\n",
    "    mse = mean_squared_error(eval_labels, eval_predictions)\n",
    "    return mse\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    \"Linear Regression\": {},\n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 10, 20]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 10, 20]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    \"ANN\": {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 70, 50, 20)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'learning_rate_init': [0.001, 0.0005, 0.0001]\n",
    "    }\n",
    "}\n",
    "# Initialize models including the ANN model\n",
    "models = {\n",
    "    # \"Linear Regression\": LinearRegression(),\n",
    "    # \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    # \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    # \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"ANN\": _build_ann_model()  # Include the ANN model here\n",
    "}\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(model, param_grid, X_train, X_test, y_train, y_test):\n",
    "    if isinstance(model, MLPRegressor):\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        _train_ann_model(best_model, X_train, y_train)\n",
    "        mse = _evaluate_ann_model(best_model, X_test, y_test)\n",
    "        return mse, np.sqrt(mse), None, best_model\n",
    "    else:\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        return mse, rmse, r2, best_model\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "    mse, rmse, r2, best_model = evaluate_model(model, param_grid, X_train, X_test, y_train, y_test)\n",
    "    results[model_name] = {\"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "    best_models[model_name] = best_model\n",
    "\n",
    "# Print the results\n",
    "for model_name, metrics in results.items():\n",
    "    if metrics['R2'] is not None:\n",
    "        print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, RMSE: {metrics['RMSE']:.4f}, R2: {metrics['R2']:.4f}\")\n",
    "    else:\n",
    "        print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, RMSE: {metrics['RMSE']:.4f}\")\n",
    "\n",
    "# Print the best model for each algorithm\n",
    "for model_name, best_model in best_models.items():\n",
    "    print(f\"Best model for {model_name}: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63935ce4-fcd0-4fed-aea4-77c271bf86da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d97f2-aa2a-4dac-9a50-fc5044bc561d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a4eda-94cd-479f-9b53-f606c4cbcd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04fee8-2b70-4f84-8f39-4588f5b3e9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e23e0-ac02-4f68-b2d2-d1afd4fe4770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091f4b1-1c0e-44a2-8746-cff7a03c071e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b183b4b-eb0f-4319-99e5-40bb669823cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a7f35-c085-419c-aea1-cd026c074da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad9e02-d585-4b9f-9b2a-3dbe026a828e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5227e8d-4ef5-48e2-afe6-94f1ef5103ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb40779-2c5d-413a-8c25-9017b593ece8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4acab-637e-493b-8c76-c512a3b67ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
